# RAG_base_QnA_app

Overview
This project is a Retrieval-Augmented Generation (RAG) system that enables powerful document-based question-answering, summarization, and contextual chat. Built with LangChain, Streamlit, and Chroma or Pinecone for vector storage, the application allows users to upload PDF documents, extract and embed content, and then interact with it conversationally through a simple web interface.

How to use :
1. Clone the Repository
2. Install Dependencies
3. Run the App
4. Use the Application
   Open the app in your browser via the URL shown in the terminal.
   Enter your LLM endpoint or OpenAI API key.
   Upload one or more PDF documents.
   Click "Submit Documents" to embed and index them.
   Ask your questions in the chat input and get contextual answers.

